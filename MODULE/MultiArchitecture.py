class MultiArchitecture(nn.Module):
    def __init__(self):
        super().__init__()
        self.alayer1 = nn.Linear(8,20)
        self.alayerad = nn.Linear(20,40)
        self.alayer2 = nn.Linear(40,80)
        self.alayer3 = nn.Linear(80,40)
        self.alayerad2 = nn.Linear(40,20)
        self.alayer4 = nn.Linear(20,1)
        self.blayer1 = nn.Linear(8,20)
        self.blayerad = nn.Linear(20,40)
        self.blayer2 = nn.Linear(40,80)
        self.blayer3 = nn.Linear(80,40)
        self.blayerad2 = nn.Linear(40,20)
        self.blayer4 = nn.Linear(20,1)
        self.clayer1 = nn.Linear(2,10)
        self.clayerad = nn.Linear(10,20)
        self.clayer2 = nn.Linear(20,40)
        self.clayer3 = nn.Linear(40,20)
        self.clayerad2 = nn.Linear(20,10)
        self.clayer4 = nn.Linear(10,1)
        self.relu=nn.LeakyReLU() 
 
    def forward(self, xa, xb):
        ou = self.alayer1(xa)
        ou = self.relu(ou)
        ou = self.alayerad(ou)
        ou = self.relu(ou)
        ou = self.alayer2(ou)
        ou = self.relu(ou)
        ou = self.alayer3(ou)
        ou = self.relu(ou)
        ou = self.alayerad2(ou)
        ou = self.relu(ou)
        ou = self.alayer4(ou)
        t = self.blayer1(xb)
        t = self.relu(t)
        t = self.blayerad(t)
        t = self.relu(t)
        t = self.blayer2(t)
        t = self.relu(t)
        t = self.blayer3(t)
        t = self.relu(t)
        t = self.blayerad2(t)
        t = self.relu(t)
        t = self.blayer4(t)
        out = torch.cat((ou,t),dim=1)
        out = self.clayer1(out)
        out = self.relu(out)
        out = self.clayerad(out)
        out = self.relu(out)
        out = self.clayer2(out)
        out = self.relu(out)
        out = self.clayer3(out)
        out = self.relu(out)
        out  = self.clayerad2(out)
        out = self.relu(out)
        out = self.clayer4(out)
        return out
