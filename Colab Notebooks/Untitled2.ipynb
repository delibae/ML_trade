{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled2.ipynb","provenance":[],"mount_file_id":"12zjVY0MBGOerq79xpm32NdYMHp43Kncz","authorship_tag":"ABX9TyOE42NsRW3+rB9A09zoNVRF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"GKbZB5iBCDVB"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pu8A6bwOZ5E0","colab":{"base_uri":"https://localhost:8080/","height":508},"executionInfo":{"status":"error","timestamp":1619505422011,"user_tz":-540,"elapsed":18562,"user":{"displayName":"배한진","photoUrl":"","userId":"02370233592940809626"}},"outputId":"98ad72a0-0cc1-4cf0-d2d4-f8d378e03830"},"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.init as init\n","import matplotlib.pyplot as plt\n","from google.colab import auth\n","from google.colab import drive\n","from google.colab import files\n","import pandas as pd\n","import numpy as np\n","import torch.nn.functional as F\n","\n","#data_load\n","#(9961, 40, 16)\n","#(9961, 51)\n","train_lstm = np.load('/content/drive/MyDrive/BIG DATA/train_lstm.npy')\n","print(train_lstm.shape)\n","TF_lstm = np.load('/content/drive/MyDrive/BIG DATA/TF_lstm.npy')\n","print(TF_lstm.shape)\n","TFw = np.load('/content/drive/MyDrive/BIG DATA/TFw.npy')\n","\n","gpu = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print(gpu)\n","# for reproducibility\n","torch.manual_seed(777)\n","if gpu == 'cuda':\n","    torch.cuda.manual_seed_all(777)\n","train1 = torch.FloatTensor(train_lstm)\n","print(train1.shape)\n","train = train1[0:40000,:,:].to(gpu)\n","trainv = train1[40000:,:,:].to(gpu)\n","\n","TF1 = torch.IntTensor(TF_lstm)\n","print(TF1.shape)\n","TF = TF1[0:40000]\n","TF = TF.type(torch.LongTensor).to(gpu)\n","# TF = torch.squeeze(TF,dim=0).to(gpu)\n","TFv = TF1[40000:]\n","\n","TFv = TFv.type(torch.LongTensor).to(gpu)\n","# TFv = torch.squeeze(TFv).to(gpu)\n","# TFw1 = torch.FloatTensor(TFw)\n","# TFw = TFw1[0:40000,:]\n","# TFwv = TFw1[40000:,:]\n","#model sequence\n","class SingleRNN(nn.Module):\n","\n","    def __init__(self, input_size, hidden_size, dropout=0, bidirectional=False):\n","        super(SingleRNN, self).__init__()\n","        \n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.num_direction = int(bidirectional) + 1\n","        self.rnn = nn.LSTM(input_size, hidden_size, num_layers = 3, dropout=dropout, batch_first=True, bidirectional=bidirectional)\n","        self.fc2 = nn.Linear(16,1)\n","        self.softmax = nn.Softmax(dim=-1)\n","        \n","        \n","\n","    def forward(self, input):\n","        # input shape: batch, seq, dim\n","        output = input\n","        rnn_output, _ = self.rnn(output)\n","        rnn_output = rnn_output[:,-1,:]\n","        softmax = self.softmax(rnn_output)\n","        softmax = torch.squeeze(softmax, dim = 0)\n","        fc = self.fc2(softmax)\n","        return fc\n","\n","\n","      \n","\n","\n","model = SingleRNN(input_size=16,hidden_size = 16, dropout = 0, bidirectional= False).to(gpu)\n","output1 = model(train)\n","# modelv = SingleRNN(input_size=16,hidden_size = 51, dropout = 0, bidirectional= False)\n","\n","optimizer = optim.Adam(model.parameters(), lr=0.01)\n","best_model_wts = model.state_dict() \n","best_acc = 0\n","best_epoch = 0\n","criterion = nn.CrossEntropyLoss()\n","l_array = []\n","a_array = []\n","for epoch in range(1000):\n","  for i in range(2):\n","    if i == 0:\n","      output = model(train)\n","      # loss = (torch.abs((output - TF))).mean()\n","\n","      loss = criterion(output, TF)\n","      # loss1 = loss.tolist()\n","      # l_array.append(loss1)\n","\n","      if (epoch + 1) % 100 == 0:\n","        print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(loss))\n","      \n","      optimizer.zero_grad()\n","      loss.backward()\n","      optimizer.step()\n","    else:\n","      pass\n","    \n","    if i == 1:\n","      pred = model(trainv)\n","      accuracy = criterion(pred,TFv)\n","      # ac1 = accuracy.tolist()\n","      # a_array.append(ac1)\n","      if best_acc > accuracy:\n","        best_model_wts = model.state_dict()\n","        best_acc = accuracy\n","        best_ephoch = epoch\n","      if (epoch+1) % 100 == 0:\n","        print('Epoch:', '%04d' % (epoch + 1), 'accuracy =', '{:.6f}'.format(accuracy))\n","    else:\n","      pass\n","\n","# plt.plot(l_array, 'r')\n","# plt.plot(a_array,'b')\n","# plt.show()\n","model_save_name = 'classifierL.pt'\n","path = F\"/content/drive/My Drive/{model_save_name}\" \n","torch.save(model.state_dict(), path)\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["(49961, 40, 16)\n","(49961,)\n","cuda\n","torch.Size([49961, 40, 16])\n","torch.Size([49961])\n"],"name":"stdout"},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-180c10ea0919>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`"]}]}]}